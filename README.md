# Game Scraper

Professional **GAME.es** web scraper that extracts **Warhammer 40k** product data:

- Title, price, ratings, **related products** (007 First Light, GTA V)
- **JSON + CSV** output with timestamps
- **Pydantic** validation + **pytest** coverage
- **uv** modern tooling

---

## ğŸ® Demo Output

**data/products_20260201_221200.json**
```json
{
  "title": "Warhammer 40.000 Space Marine II",
  "price": "34'99â‚¬",
  "ratings_count": "208 Valoraciones",
  "related_products": [
    { "name": "007 First Light", "price": "69'99â‚¬" },
    { "name": "Grand Theft Auto V", "price": "19'99â‚¬" }
  ]
}
```
---

## ğŸš€ Quick Start
## Clone & Virtual Environment

git clone <repo> game-scraper
cd game-scraper
python -m venv venv
source venv/bin/activate   # Linux / Mac
.# venv\Scripts\activate    # Windows

## uv setup (IMPORTANT)

pip install uv
uv sync --dev
uv pip install -e .

## Run scraper

uv run python -m src.game_scraper.main

## Run tests

uv run pytest tests/ -v

# ğŸ“ Project Structure

src/game_scraper/     # Core scraper + parser
tests/               # pytest + HTML samples
data/                # JSON + CSV output
config.toml          # GAME.es selectors

## ğŸ§ª Tests & Coverage

uv run pytest --cov=src/game_scraper/ tests/

# ğŸ”§ Troubleshooting (uv / pytest)

## Error:
ModuleNotFoundError: No module named 'src'

## Solution:
uv pip install -e .

## Alternative (run tests from ROOT):
PYTHONPATH=src pytest

# ğŸ§  Main Entrypoint

src/game_scraper/main.py

## ğŸ³ Docker
```bash
### Quick Docker Run

docker-compose up --build
# Files saved â†’ data/products_*.json (persistent volume)
```

### Single Run
```bash
docker-compose run --rm game-scraper
```

### Verify Data Persistence
```bash
ls -la data/  # JSON + CSV files locally!
```

### Docker Compose Services
```bash
game-scraper:
  âœ… Image: python:3.12-slim (~150MB)
  âœ… Volume: ./data:/app/data (persistent)
  âœ… pip deps: requests + beautifulsoup4
  âœ… CMD: python -m src.game_scraper.main
```

### â° CRONJOB PRODUCTION (cada 2 minutos)

Cronjob configurado para ejecutar el scraper automÃ¡ticamente en entorno de producciÃ³n, generando archivos persistentes cada 2 minutos mediante Docker.

- EjecuciÃ³n automÃ¡tica cada 2 minutos

- GeneraciÃ³n de archivos JSON + CSV con timestamp

- Logs accesibles desde Docker y dentro del contenedor

- Compatible con Windows + Git Bash usando MSYS_NO_PATHCONV=1

### ğŸ¯ Step 3 â€“ Resumen

âœ… Cron ejecuta el scraper cada 2 minutos

âœ… Archivos generados:
data/products_YYYYMMDD_HHMMSS.json
data/products_YYYYMMDD_HHMMSS.csv

âœ… Logs disponibles en:

docker-compose logs -f

/var/log/cron/scraper.log

âœ… Volumen persistente en Windows (Git Bash compatible)

### ğŸš€ Comandos Git Bash (Windows)
## Inicio (cron automÃ¡tico)
MSYS_NO_PATHCONV=1 docker-compose up -d --build

## Ver logs en vivo (ejecuciÃ³n cada 2 minutos)
MSYS_NO_PATHCONV=1 docker-compose logs -f

## Detener el servicio
MSYS_NO_PATHCONV=1 docker-compose down

## Ver archivos generados localmente
ls -la data/      # En Windows: dir data\

### ğŸ“ docker-compose.yml
```bash
services:
  game-scraper:
    build: .
    container_name: game-scraper-cron
    volumes:
      - type: bind
        source: "./data"
        target: "/app/data"
    restart: unless-stopped
```

### âœ… Output Esperado
data/products_20260202_013000.json
data/products_20260202_013000.csv
data/products_20260202_013200.json
data/products_20260202_013200.csv


Todos los archivos se generan localmente en la carpeta data/ cada 2 minutos.

### ğŸ”§ Troubleshooting (Windows / Git Bash)
## Problema

Se crea una carpeta incorrecta llamada data;C.

### SoluciÃ³n

#### Usar siempre:
```bash
MSYS_NO_PATHCONV=1 docker-compose up -d
```

### Alternativa directa con Docker:
```bash
docker run -v "$(pwd)/data:/app/data"
```
### ğŸ“Š MÃ©tricas Step 3

- Cron frequency: */2 * * * * (cada 2 minutos)

- Archivos generados: 720 por dÃ­a (JSON + CSV)

- TamaÃ±o estimado: ~50 KB por ejecuciÃ³n

- Uso diario: ~36 MB / dÃ­a

- Almacenamiento: volumen local persistente (data/)
